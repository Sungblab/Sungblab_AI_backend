from typing import List, Optional, Dict, Any
from sqlalchemy.orm import Session
from sqlalchemy import and_, desc, func, text
from app.models.embedding import ProjectEmbedding
from pydantic import BaseModel
from datetime import datetime
import numpy as np


class ProjectEmbeddingCreate(BaseModel):
    project_id: str
    file_id: str
    file_name: str
    chunk_index: int
    chunk_text: str
    embedding_vector: List[float]
    embedding_model: str = "text-embedding-004"
    task_type: str = "RETRIEVAL_DOCUMENT"
    chunk_size: int
    similarity_threshold: float = 0.7


class ProjectEmbeddingUpdate(BaseModel):
    file_name: Optional[str] = None
    chunk_text: Optional[str] = None
    embedding_vector: Optional[List[float]] = None
    similarity_threshold: Optional[float] = None


def create(db: Session, *, obj_in: ProjectEmbeddingCreate) -> ProjectEmbedding:
    """ì„ë² ë”© ìƒì„± (pgvector Vector íƒ€ì…)"""
    # ğŸ”¥ Vector íƒ€ì…ìœ¼ë¡œ ì§ì ‘ ì „ë‹¬ (ì •ê·œí™”í•˜ì§€ ì•ŠìŒ)
    embedding_vector = obj_in.embedding_vector
    
    db_obj = ProjectEmbedding(
        project_id=obj_in.project_id,
        file_id=obj_in.file_id,
        file_name=obj_in.file_name,
        chunk_index=obj_in.chunk_index,
        chunk_text=obj_in.chunk_text,
        embedding_vector=embedding_vector,  # List[float] -> Vector(768) ìë™ ë³€í™˜
        embedding_model=obj_in.embedding_model,
        task_type=obj_in.task_type,
        chunk_size=obj_in.chunk_size,
        similarity_threshold=obj_in.similarity_threshold
    )
    db.add(db_obj)
    db.commit()
    db.refresh(db_obj)
    return db_obj


def create_embedding(
    db: Session,
    *,
    project_id: str,
    file_id: str,
    file_name: str,
    chunk_index: int,
    chunk_text: str,
    embedding_vector: List[float],
    embedding_model: str = "text-embedding-004",
    task_type: str = "RETRIEVAL_DOCUMENT",
    chunk_size: int,
    similarity_threshold: float = 0.7
) -> ProjectEmbedding:
    """ì„ë² ë”© ìƒì„±"""
    embedding_data = ProjectEmbeddingCreate(
        project_id=project_id,
        file_id=file_id,
        file_name=file_name,
        chunk_index=chunk_index,
        chunk_text=chunk_text,
        embedding_vector=embedding_vector,
        embedding_model=embedding_model,
        task_type=task_type,
        chunk_size=chunk_size,
        similarity_threshold=similarity_threshold
    )
    return create(db, obj_in=embedding_data)


def get_by_project(db: Session, project_id: str) -> List[ProjectEmbedding]:
    """í”„ë¡œì íŠ¸ë³„ ëª¨ë“  ì„ë² ë”© ì¡°íšŒ"""
    return db.query(ProjectEmbedding).filter(
        ProjectEmbedding.project_id == project_id
    ).order_by(ProjectEmbedding.file_name, ProjectEmbedding.chunk_index).all()


def get_by_file(db: Session, project_id: str, file_id: str) -> List[ProjectEmbedding]:
    """íŠ¹ì • íŒŒì¼ì˜ ëª¨ë“  ì„ë² ë”© ì¡°íšŒ"""
    return db.query(ProjectEmbedding).filter(
        and_(
            ProjectEmbedding.project_id == project_id,
            ProjectEmbedding.file_id == file_id
        )
    ).order_by(ProjectEmbedding.chunk_index).all()


def delete_by_file(db: Session, project_id: str, file_id: str) -> int:
    """íŒŒì¼ë³„ ì„ë² ë”© ì‚­ì œ"""
    deleted = db.query(ProjectEmbedding).filter(
        and_(
            ProjectEmbedding.project_id == project_id,
            ProjectEmbedding.file_id == file_id
        )
    ).delete()
    db.commit()
    return deleted


def delete_by_project(db: Session, project_id: str) -> int:
    """í”„ë¡œì íŠ¸ë³„ ëª¨ë“  ì„ë² ë”© ì‚­ì œ"""
    deleted = db.query(ProjectEmbedding).filter(
        ProjectEmbedding.project_id == project_id
    ).delete()
    db.commit()
    return deleted


def get_embedding_stats(db: Session, project_id: str) -> Dict[str, Any]:
    """ì„ë² ë”© í†µê³„ ì¡°íšŒ"""
    stats = db.query(
        func.count(ProjectEmbedding.id).label('total_embeddings'),
        func.count(func.distinct(ProjectEmbedding.file_id)).label('unique_files'),
        func.avg(ProjectEmbedding.chunk_size).label('avg_chunk_size'),
        func.sum(ProjectEmbedding.chunk_size).label('total_chars')
    ).filter(
        ProjectEmbedding.project_id == project_id
    ).first()
    
    return {
        'total_embeddings': stats.total_embeddings or 0,
        'unique_files': stats.unique_files or 0,
        'avg_chunk_size': float(stats.avg_chunk_size) if stats.avg_chunk_size else 0,
        'total_chars': stats.total_chars or 0
    }


# ğŸ” pgvector ë„¤ì´í‹°ë¸Œ ë²¡í„° ê²€ìƒ‰ (ê³ ì„±ëŠ¥)
def search_similar(
    db: Session,
    project_id: str,
    query_embedding: List[float],
    top_k: int = 5,
    threshold: float = 0.4
) -> List[Dict[str, Any]]:
    """
    pgvector ë„¤ì´í‹°ë¸Œ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
    - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (pgvector ìµœì í™”)
    - HNSW ì¸ë±ìŠ¤ í™œìš©ìœ¼ë¡œ ê³ ì„±ëŠ¥ ê²€ìƒ‰
    """
    try:
        print(f"ğŸ” ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ ì‹œì‘ (pgvector ë„¤ì´í‹°ë¸Œ): top_k={top_k}, threshold={threshold}")
        print(f"   í”„ë¡œì íŠ¸ ID: {project_id}")
        
        # pgvector ë„¤ì´í‹°ë¸Œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰
        results = db.query(
            ProjectEmbedding.id,
            ProjectEmbedding.project_id,
            ProjectEmbedding.file_id,
            ProjectEmbedding.file_name,
            ProjectEmbedding.chunk_index,
            ProjectEmbedding.chunk_text,
            ProjectEmbedding.embedding_model,
            ProjectEmbedding.task_type,
            ProjectEmbedding.chunk_size,
            ProjectEmbedding.created_at,
            # pgvector ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì—°ì‚° (1 - ì½”ì‚¬ì¸ ê±°ë¦¬)
            (1 - ProjectEmbedding.embedding_vector.cosine_distance(query_embedding)).label('similarity')
        ).filter(
            ProjectEmbedding.project_id == project_id
        ).filter(
            # ì„ê³„ê°’ í•„í„°ë§ (ì½”ì‚¬ì¸ ê±°ë¦¬ ê¸°ì¤€)
            ProjectEmbedding.embedding_vector.cosine_distance(query_embedding) < (1 - threshold)
        ).order_by(
            ProjectEmbedding.embedding_vector.cosine_distance(query_embedding)
        ).limit(top_k).all()
        
        # ê²°ê³¼ ë³€í™˜
        search_results = []
        for result in results:
            search_results.append({
                "id": result.id,
                "project_id": result.project_id,
                "file_id": result.file_id,
                "file_name": result.file_name,
                "chunk_index": result.chunk_index,
                "content": result.chunk_text,
                "similarity": float(result.similarity),
                "embedding_model": result.embedding_model,
                "task_type": result.task_type,
                "chunk_size": result.chunk_size,
                "created_at": result.created_at.isoformat() if result.created_at else None
            })
        
        print(f"âœ… pgvector ë„¤ì´í‹°ë¸Œ ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
        for i, result in enumerate(search_results):
            print(f"   [{i+1}] ìœ ì‚¬ë„: {result['similarity']:.3f}, íŒŒì¼: {result['file_name']}")
        
        return search_results
        
    except Exception as e:
        print(f"âŒ pgvector ë„¤ì´í‹°ë¸Œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        print("   í´ë°± ê²€ìƒ‰ ëª¨ë“œë¡œ ì „í™˜...")
        return _fallback_search_similar(db, project_id, query_embedding, top_k, threshold)


def _normalize_embedding_vector(embedding_vector: List[float]) -> List[float]:
    """ì„ë² ë”© ë²¡í„° ì •ê·œí™”"""
    try:
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        vec = np.array(embedding_vector, dtype=np.float32)
        
        # ì •ê·œí™” (L2 norm)
        norm = np.linalg.norm(vec)
        if norm == 0:
            return vec.tolist()
        
        normalized = vec / norm
        return normalized.tolist()
        
    except Exception as e:
        print(f"ë²¡í„° ì •ê·œí™” ì˜¤ë¥˜: {e}")
        return embedding_vector


def _fallback_search_similar(
    db: Session,
    project_id: str,
    query_embedding: List[float],
    top_k: int = 5,
    threshold: float = 0.7
) -> List[Dict[str, Any]]:
    """í´ë°±: ê¸°ì¡´ ë°©ì‹ì˜ ìœ ì‚¬ë„ ê²€ìƒ‰"""
    print("âš ï¸  í´ë°± ê²€ìƒ‰ ëª¨ë“œ ì‚¬ìš© (ì„±ëŠ¥ ì €í•˜)")
    
    embeddings = get_by_project(db, project_id)
    
    if not embeddings:
        return []
    
    # ìœ ì‚¬ë„ ê³„ì‚°
    similarities = []
    for embedding in embeddings:
        similarity = _calculate_cosine_similarity_fallback(
            query_embedding, 
            embedding.embedding_vector
        )
        
        if similarity >= threshold:
            similarities.append({
                "id": embedding.id,
                "project_id": embedding.project_id,
                "file_id": embedding.file_id,
                "file_name": embedding.file_name,
                "chunk_index": embedding.chunk_index,
                "content": embedding.chunk_text,
                "similarity": similarity,
                "embedding_model": embedding.embedding_model,
                "task_type": embedding.task_type,
                "chunk_size": embedding.chunk_size,
                "created_at": embedding.created_at.isoformat() if embedding.created_at else None
            })
    
    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ kê°œ ë°˜í™˜
    similarities.sort(key=lambda x: x["similarity"], reverse=True)
    return similarities[:top_k]


def _calculate_cosine_similarity_fallback(vec1: List[float], vec2: List[float]) -> float:
    """í´ë°±: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    try:
        # numpy ì‚¬ìš©
        v1 = np.array(vec1, dtype=np.float32)
        v2 = np.array(vec2, dtype=np.float32)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        dot_product = np.dot(v1, v2)
        norm_v1 = np.linalg.norm(v1)
        norm_v2 = np.linalg.norm(v2)
        
        if norm_v1 == 0 or norm_v2 == 0:
            return 0.0
        
        similarity = dot_product / (norm_v1 * norm_v2)
        return float(similarity)
        
    except Exception as e:
        print(f"ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return 0.0


def batch_create_embeddings(
    db: Session,
    embeddings_data: List[ProjectEmbeddingCreate]
) -> List[ProjectEmbedding]:
    """ë°°ì¹˜ ì„ë² ë”© ìƒì„± (pgvector Vector íƒ€ì… ìµœì í™”)"""
    embeddings = []
    
    try:
        # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ
        for data in embeddings_data:
            # ğŸ”¥ ì¤‘ìš”: Vector íƒ€ì…ìœ¼ë¡œ ì§ì ‘ ì „ë‹¬ (ì •ê·œí™”í•˜ì§€ ì•ŠìŒ)
            # pgvectorê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ë„ë¡ List[float] ê·¸ëŒ€ë¡œ ì „ë‹¬
            embedding_vector = data.embedding_vector
            
            embedding = ProjectEmbedding(
                project_id=data.project_id,
                file_id=data.file_id,
                file_name=data.file_name,
                chunk_index=data.chunk_index,
                chunk_text=data.chunk_text,
                embedding_vector=embedding_vector,  # List[float] -> Vector(768) ìë™ ë³€í™˜
                embedding_model=data.embedding_model,
                task_type=data.task_type,
                chunk_size=data.chunk_size,
                similarity_threshold=data.similarity_threshold
            )
            embeddings.append(embedding)
        
        # ë°°ì¹˜ insert
        db.add_all(embeddings)
        db.commit()
        
        # refresh ëª¨ë“  ê°ì²´
        for embedding in embeddings:
            db.refresh(embedding)
        
        print(f"âœ… ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì™„ë£Œ: {len(embeddings)}ê°œ")
        return embeddings
        
    except Exception as e:
        print(f"âŒ ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        db.rollback()
        return [] 